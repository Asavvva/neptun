{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Sampler\n",
    "import random\n",
    "import os\n",
    "import fnmatch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from MLP import MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyDataPreparationLSTM import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(directory, pattern, maxdepth=None):\n",
    "    flist = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for basename in files:\n",
    "            if fnmatch.fnmatch(basename, pattern):\n",
    "                filename = os.path.join(root, basename)\n",
    "                filename = filename.replace('\\\\\\\\', os.sep)\n",
    "                if maxdepth is None:\n",
    "                    flist.append(filename)\n",
    "                else:\n",
    "                    if filename.count(os.sep)-directory.count(os.sep) <= maxdepth:\n",
    "                        flist.append(filename)\n",
    "    return flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_files_pkl = find_files('/mnt/hippocamp/asavin/data/wind/wind_arrays_kara_norm', '*.pkl')\n",
    "wind_files_pkl.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(wind_files_pkl, num_days=14, num_years=1)\n",
    "dataset.select_random_years()\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_autoencoder_name = 'wind_pre_autoencoder_run002'\n",
    "lstm2D_name = 'wind_pre_lstm2D_run003'\n",
    "\n",
    "pretrained_encoder = torch.load(f'/app/Kara_plume_movement/wind/models/model_{pretrained_autoencoder_name}_encoder.pth', map_location=torch.device('cpu'))\n",
    "lstm_network = torch.load(f'/app/Kara_plume_movement/wind/models/model_{lstm2D_name}_lstm_network.pth', map_location=torch.device('cpu'))\n",
    "lstm_decoder = torch.load(f'/app/Kara_plume_movement/wind/models/model_{lstm2D_name}_MLPdecoder.pth', map_location=torch.device('cpu'))\n",
    "pretrained_decoder = torch.load(f'/app/Kara_plume_movement/wind/models/model_{pretrained_autoencoder_name}_decoder.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_encoder = pretrained_encoder.cuda()\n",
    "lstm_network = lstm_network.cuda()\n",
    "lstm_decoder = lstm_decoder.cuda()\n",
    "pretrained_decoder = pretrained_decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_encoder.eval();\n",
    "lstm_network.eval();\n",
    "lstm_decoder.eval();\n",
    "pretrained_decoder.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function=torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    data_gpu = data.to(device='cuda', dtype=torch.float)\n",
    "\n",
    "    data_list = data_gpu.unbind(dim=1)\n",
    "    encoded_data_list = [pretrained_encoder.forward(t) for t in data_list]\n",
    "    decoded_target_list = [pretrained_decoder.forward(t) for t in encoded_data_list]\n",
    "\n",
    "    wind_vector = torch.stack(encoded_data_list, dim=1)\n",
    "\n",
    "    encoded_data, (_, _) = lstm_network.forward(wind_vector)\n",
    "    split_tensors = encoded_data.unbind(dim=1)\n",
    "    processed_tensors = [pretrained_decoder.forward(lstm_decoder.forward(t)) for t in split_tensors]\n",
    "    decoded_data = torch.stack(processed_tensors, dim=1)\n",
    "    \n",
    "    decoded_target = torch.stack(decoded_target_list, dim=1)\n",
    "\n",
    "    loss = loss_function(decoded_target, decoded_data)\n",
    "    test_loss = loss.detach() * dataloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_target.shape, decoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawing(tensor1, tensor2, indexes):\n",
    "    for i in indexes:\n",
    "        for j in range(tensor1.shape[1]):\n",
    "            # Извлечение частей тензоров\n",
    "            extracted_tensor1_0 = tensor1[i, j, 0, :, :]\n",
    "            extracted_tensor1_1 = tensor1[i, j, 1, :, :]\n",
    "            extracted_tensor2_0 = tensor2[i, j, 0, :, :]\n",
    "            extracted_tensor2_1 = tensor2[i, j, 1, :, :]\n",
    "\n",
    "            # Конвертация в numpy\n",
    "            array1_0 = extracted_tensor1_0.detach().cpu().numpy()\n",
    "            array1_1 = extracted_tensor1_1.detach().cpu().numpy()\n",
    "            array2_0 = extracted_tensor2_0.detach().cpu().numpy()\n",
    "            array2_1 = extracted_tensor2_1.detach().cpu().numpy()\n",
    "\n",
    "            # Получение общих минимумов/максимумов для нормализации отображения\n",
    "            vmin = min(array1_0.min(), array1_1.min(), array2_0.min(), array2_1.min())\n",
    "            vmax = max(array1_0.max(), array1_1.max(), array2_0.max(), array2_1.max())\n",
    "\n",
    "            # Построение графиков\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "            \n",
    "            # Tensor 1\n",
    "            axs[0, 0].imshow(array1_0, cmap='viridis', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "            axs[0, 0].set_title('Tensor1 U')\n",
    "\n",
    "            axs[1, 0].imshow(array1_1, cmap='viridis', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "            axs[1, 0].set_title('Tensor1 V')\n",
    "\n",
    "            # Tensor 2\n",
    "            axs[0, 1].imshow(array2_0, cmap='viridis', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "            axs[0, 1].set_title('Tensor2 U')\n",
    "\n",
    "            axs[1, 1].imshow(array2_1, cmap='viridis', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "            axs[1, 1].set_title('Tensor2 V')\n",
    "\n",
    "            # Добавление единого цветового бара\n",
    "            cbar = fig.colorbar(axs[0, 0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "            cbar.ax.set_ylabel('wind speed')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        print('--------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing(decoded_data, decoded_target, [i for i in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
